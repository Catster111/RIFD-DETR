#!/usr/bin/env python3

"""Evaluate FDDB recall@FP=100 under in-plane rotations (Up/Down/Left/Right)."""

from __future__ import annotations

import argparse
import math
import os
import sys
import time
from collections import defaultdict
from typing import Dict, Iterable, List, Optional, Sequence, Tuple

import torch
from PIL import Image
from torchvision import transforms
from torchvision.ops import box_convert

sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), '..'))

from src.core import YAMLConfig
from src.core.yaml_utils import parse_cli as parse_update


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser('FDDB rotational evaluation')
    parser.add_argument('-c', '--config', required=True, help='Path to YAML config')
    parser.add_argument('--checkpoint', required=True, help='Model checkpoint (.pth)')
    parser.add_argument('--image-root', help='Root directory of FDDB images (for on-the-fly rotations)')
    parser.add_argument('--label-file', help='FDDB label file (rect format) for original dataset')
    parser.add_argument('--rot-root', help='Root generated by generate_fddb_rotated_sets.py (preferred)')
    parser.add_argument('--rotations', nargs='+', default=['right', 'left', 'up', 'down'],
                        help='Subset of {right,left,up,down}')
    parser.add_argument('--fp-target', type=int, default=100, help='FP budget for recall calculation')
    parser.add_argument('--score-threshold', type=float, default=0.0,
                        help='Optional score threshold to filter detections before evaluation')
    parser.add_argument('--device', type=str, default=None, help='Force device (e.g., cpu)')
    parser.add_argument('-u', '--update', nargs='+', default=None, help='Override YAML entries')
    args = parser.parse_args()

    if args.rot_root:
        if not os.path.isdir(args.rot_root):
            parser.error(f'--rot-root path not found: {args.rot_root}')
    else:
        if not args.image_root or not args.label_file:
            parser.error('Either provide --rot-root or both --image-root and --label-file for on-the-fly rotations.')
        if not os.path.isdir(args.image_root):
            parser.error(f'--image-root path not found: {args.image_root}')
        if not os.path.isfile(args.label_file):
            parser.error(f'--label-file path not found: {args.label_file}')

    return args


def load_config_and_model(cfg_path: str, checkpoint: str, update_args, forced_device: Optional[str]):
    overrides = parse_update(update_args) if update_args else {}
    cfg = YAMLConfig(cfg_path, **overrides)
    model = cfg.model
    post = cfg.postprocessor

    state = torch.load(checkpoint, map_location='cpu')

    def _load(module, sd):
        try:
            module.load_state_dict(sd)
        except RuntimeError as exc:
            missing, unexpected = module.load_state_dict(sd, strict=False)
            print(f'⚠️  Partial load into {module.__class__.__name__}: {exc}')
            if missing:
                print(f'   missing({len(missing)}): {missing[:5]} ...')
            if unexpected:
                print(f'   unexpected({len(unexpected)}): {unexpected[:5]} ...')

    _load(model, state.get('model', state))
    if 'postprocessor' in state and post is not None:
        _load(post, state['postprocessor'])

    if forced_device:
        device = torch.device(forced_device)
    else:
        device = torch.device(cfg.device if cfg.device else ('cuda' if torch.cuda.is_available() else 'cpu'))
    model.to(device).eval()
    if post is not None:
        post.to(device).eval()
    return cfg, model, post, device


def parse_fddb_labels(label_path: str) -> List[Tuple[str, List[List[float]]]]:
    entries: List[Tuple[str, List[List[float]]]] = []
    current: Optional[str] = None
    boxes: List[List[float]] = []
    with open(label_path, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            if line.startswith('#'):
                if current is not None:
                    entries.append((current, boxes))
                current = line[1:].strip()
                boxes = []
            else:
                xs = line.split()
                if len(xs) < 4:
                    continue
                x1, y1, x2, y2 = map(float, xs[:4])
                boxes.append([x1, y1, x2, y2])
    if current is not None:
        entries.append((current, boxes))
    return entries


def rotate_points(points: Iterable[Tuple[float, float]], width: float, height: float, angle_deg: int) -> List[Tuple[float, float]]:
    angle_rad = math.radians(angle_deg % 360)
    sin_a = math.sin(angle_rad)
    cos_a = math.cos(angle_rad)
    old_cx, old_cy = width / 2.0, height / 2.0
    if angle_deg % 180 == 0:
        new_cx, new_cy = width / 2.0, height / 2.0
    else:
        new_cx, new_cy = height / 2.0, width / 2.0

    rotated: List[Tuple[float, float]] = []
    for x, y in points:
        x0 = x - old_cx
        y0 = y - old_cy
        xr = x0 * cos_a + y0 * sin_a
        yr = -x0 * sin_a + y0 * cos_a
        rotated.append((xr + new_cx, yr + new_cy))
    return rotated


def rotate_box(box: List[float], width: float, height: float, angle_deg: int) -> List[float]:
    x1, y1, x2, y2 = box
    corners = [(x1, y1), (x2, y1), (x1, y2), (x2, y2)]
    rotated = rotate_points(corners, width, height, angle_deg)
    xs = [p[0] for p in rotated]
    ys = [p[1] for p in rotated]
    return [min(xs), min(ys), max(xs), max(ys)]


def clamp_box(box: List[float], width: float, height: float) -> Optional[List[float]]:
    x1, y1, x2, y2 = box
    x1 = max(0.0, min(width, x1))
    y1 = max(0.0, min(height, y1))
    x2 = max(0.0, min(width, x2))
    y2 = max(0.0, min(height, y2))
    if x2 <= x1 or y2 <= y1:
        return None
    return [x1, y1, x2, y2]


def rotate_image_and_boxes(img: Image.Image, boxes: List[List[float]], orientation: str) -> Tuple[Image.Image, List[List[float]]]:
    orientation = orientation.lower()
    if orientation == 'right':
        angle = 0
        rotated = img
    elif orientation == 'left':
        angle = 180
        rotated = img.transpose(Image.ROTATE_180)
    elif orientation == 'up':
        angle = 90
        rotated = img.transpose(Image.ROTATE_90)
    elif orientation == 'down':
        angle = 270
        rotated = img.transpose(Image.ROTATE_270)
    else:
        raise ValueError(f'Unsupported orientation: {orientation}')

    width, height = img.size
    new_width, new_height = rotated.size
    rotated_boxes: List[List[float]] = []
    for box in boxes:
        rot = rotate_box(box, width, height, angle)
        clamped = clamp_box(rot, new_width, new_height)
        if clamped is not None:
            rotated_boxes.append(clamped)
    return rotated, rotated_boxes


def compute_recall_at_fp(preds_by_image: Dict[int, List[Tuple[List[float], float]]],
                         gt_by_image: Dict[int, List[List[float]]],
                         fp_target: int,
                         iou_thr: float = 0.5) -> Tuple[float, int, int]:
    total_gt = sum(len(gts) for gts in gt_by_image.values())
    if total_gt == 0:
        return 0.0, 0, 0

    all_preds: List[Tuple[float, int, List[float]]] = []
    for img_id, dets in preds_by_image.items():
        for box, score in dets:
            all_preds.append((score, img_id, box))
    all_preds.sort(key=lambda x: x[0], reverse=True)

    matched = {img_id: [False] * len(gts) for img_id, gts in gt_by_image.items()}
    tp = fp = 0
    recall_at_target = 0.0

    for score, img_id, box in all_preds:
        gt_boxes = gt_by_image.get(img_id, [])
        best_iou = 0.0
        best_idx = -1
        for idx, gt_box in enumerate(gt_boxes):
            if matched[img_id][idx]:
                continue
            ix1 = max(box[0], gt_box[0])
            iy1 = max(box[1], gt_box[1])
            ix2 = min(box[2], gt_box[2])
            iy2 = min(box[3], gt_box[3])
            iw = max(0.0, ix2 - ix1)
            ih = max(0.0, iy2 - iy1)
            if iw <= 0 or ih <= 0:
                continue
            inter = iw * ih
            union = (box[2] - box[0]) * (box[3] - box[1]) + (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1]) - inter
            if union <= 0:
                continue
            iou = inter / union
            if iou > best_iou:
                best_iou = iou
                best_idx = idx
        if best_iou >= iou_thr and best_idx >= 0:
            matched[img_id][best_idx] = True
            tp += 1
        else:
            fp += 1
        if fp >= fp_target:
            recall_at_target = tp / total_gt
            break

    if fp < fp_target:
        recall_at_target = tp / total_gt
    return recall_at_target, tp, fp


def compute_ap_at_fp(preds_by_image: Dict[int, List[Tuple[List[float], float]]],
                     gt_by_image: Dict[int, List[List[float]]],
                     fp_target: int,
                     iou_thr: float = 0.5) -> Tuple[float, List[float], List[float], int, int]:
    """Compute AP truncated at a given FP budget.

    Builds a precision-recall curve by sweeping score thresholds (via sorted detections),
    but only integrates area until cumulative FP reaches fp_target.

    Returns:
        ap_at_fp: truncated AP in [0,1]
        precisions: precision values along the sweep (truncated)
        recalls: recall values along the sweep (truncated)
        tp: final cumulative true positives at truncation
        fp: final cumulative false positives at truncation
    """
    total_gt = sum(len(gts) for gts in gt_by_image.values())
    if total_gt == 0:
        return 0.0, [], [], 0, 0

    all_preds: List[Tuple[float, int, List[float]]] = []
    for img_id, dets in preds_by_image.items():
        for box, score in dets:
            all_preds.append((score, img_id, box))
    all_preds.sort(key=lambda x: x[0], reverse=True)

    matched = {img_id: [False] * len(gts) for img_id, gts in gt_by_image.items()}
    tp = fp = 0
    precisions: List[float] = []
    recalls: List[float] = []

    for score, img_id, box in all_preds:
        gt_boxes = gt_by_image.get(img_id, [])
        best_iou = 0.0
        best_idx = -1
        for idx, gt_box in enumerate(gt_boxes):
            if matched[img_id][idx]:
                continue
            ix1 = max(box[0], gt_box[0])
            iy1 = max(box[1], gt_box[1])
            ix2 = min(box[2], gt_box[2])
            iy2 = min(box[3], gt_box[3])
            iw = max(0.0, ix2 - ix1)
            ih = max(0.0, iy2 - iy1)
            if iw <= 0 or ih <= 0:
                continue
            inter = iw * ih
            union = (box[2] - box[0]) * (box[3] - box[1]) + (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1]) - inter
            if union <= 0:
                continue
            iou = inter / union
            if iou > best_iou:
                best_iou = iou
                best_idx = idx

        if best_iou >= iou_thr and best_idx >= 0:
            matched[img_id][best_idx] = True
            tp += 1
        else:
            fp += 1

        precisions.append(tp / max(tp + fp, 1))
        recalls.append(tp / total_gt)

        if fp >= fp_target:
            break

    if not precisions:
        return 0.0, [], [], 0, 0

    # Compute precision envelope (monotonic decreasing) and integrate area under PR curve (truncated)
    # Use standard VOC-style area: sum over recall steps of precision envelope
    mrec = [0.0] + recalls
    mpre = [0.0] + precisions
    for i in range(len(mpre) - 1, 0, -1):
        mpre[i - 1] = max(mpre[i - 1], mpre[i])

    ap = 0.0
    for i in range(1, len(mrec)):
        ap += (mrec[i] - mrec[i - 1]) * mpre[i]

    return ap, precisions, recalls, tp, fp


def main():
    args = parse_args()
    cfg, model, post, device = load_config_and_model(args.config, args.checkpoint, args.update, args.device)
    use_pre_rotated = bool(args.rot_root)
    entries_cache: Dict[str, List[Tuple[str, List[List[float]]]]] = {}

    if use_pre_rotated:
        print(f'Using pre-rotated FDDB rotations located at {args.rot_root}')
    else:
        entries = parse_fddb_labels(args.label_file)
        print(f'Loaded {len(entries)} FDDB entries from {args.label_file}')

    preprocess = transforms.Compose([
        transforms.Resize((640, 640)),
        transforms.ToTensor(),
    ])

    orientations = [rot.lower() for rot in args.rotations]
    summary: List[Tuple[str, float, float]] = []

    with torch.no_grad():
        for orientation in orientations:
            print(f"\n=== Rotation: {orientation.upper()} ===")
            preds_by_image: Dict[int, List[Tuple[List[float], float]]] = defaultdict(list)
            gt_by_image: Dict[int, List[List[float]]] = {}
            total_time = 0.0
            total_images = 0

            if use_pre_rotated:
                orientation_dir = os.path.join(args.rot_root, orientation)
                image_root = os.path.join(orientation_dir, 'images')
                label_path = os.path.join(orientation_dir, 'label.txt')
                if not os.path.isfile(label_path):
                    print(f'⚠️  Missing label file for orientation "{orientation}": {label_path}. Skipping.')
                    continue
                if not os.path.isdir(image_root):
                    print(f'⚠️  Missing images directory for orientation "{orientation}": {image_root}. Skipping.')
                    continue
                current_entries = entries_cache.get(orientation)
                if current_entries is None:
                    current_entries = parse_fddb_labels(label_path)
                    entries_cache[orientation] = current_entries
                    print(f'Loaded {len(current_entries)} FDDB entries from {label_path}')
            else:
                image_root = args.image_root
                current_entries = entries

            for idx, (rel_path, gt_boxes) in enumerate(current_entries):
                img_path = os.path.join(image_root, rel_path)
                try:
                    if use_pre_rotated:
                        rotated_img = Image.open(img_path).convert('RGB')
                        rotated_boxes = [box[:] for box in gt_boxes]
                    else:
                        image = Image.open(img_path).convert('RGB')
                        rotated_img, rotated_boxes = rotate_image_and_boxes(image, gt_boxes, orientation)
                except FileNotFoundError:
                    print(f'⚠️  Missing image for orientation "{orientation}": {img_path}. Skipping sample.')
                    continue
                width_rot, height_rot = rotated_img.size
                gt_by_image[idx] = rotated_boxes

                tensor = preprocess(rotated_img).unsqueeze(0).to(device)
                orig_sizes = torch.tensor([[height_rot, width_rot]], dtype=torch.float32, device=device)

                start = time.perf_counter()
                outputs = model(tensor)
                det = post(outputs, orig_sizes)[0]
                if device.type == 'cuda':
                    torch.cuda.synchronize()
                total_time += time.perf_counter() - start
                total_images += 1

                boxes_xywh = det.get('boxes', torch.empty(0, 4, device=device))
                scores = det.get('scores', torch.empty(0, device=device))
                if boxes_xywh.numel() == 0:
                    continue

                boxes_xywh = boxes_xywh.detach().cpu()
                scores = scores.detach().cpu()
                boxes_xyxy = box_convert(boxes_xywh, in_fmt='xywh', out_fmt='xyxy')
                boxes_xyxy[:, 0::2] = boxes_xyxy[:, 0::2].clamp(0, width_rot)
                boxes_xyxy[:, 1::2] = boxes_xyxy[:, 1::2].clamp(0, height_rot)

                for box_tensor, score in zip(boxes_xyxy, scores):
                    if score.item() < args.score_threshold:
                        continue
                    box_list = box_tensor.tolist()
                    if box_list[2] <= box_list[0] or box_list[3] <= box_list[1]:
                        continue
                    preds_by_image[idx].append((box_list, float(score)))

            recall, tp, fp = compute_recall_at_fp(preds_by_image, gt_by_image, args.fp_target)
            ap_fp, precs, recs, tp2, fp2 = compute_ap_at_fp(preds_by_image, gt_by_image, args.fp_target)
            fps = total_images / total_time if total_time > 0 else 0.0
            print(f'Recall@FP={args.fp_target}: {recall * 100:.2f}% (TP={tp}, FP={fp})')
            print(f'AP@FP={args.fp_target}: {ap_fp * 100:.2f}%')
            print(f'FPS: {fps:.2f}')
            summary.append((orientation, recall, ap_fp, fps))

    if summary:
        order = {'up': 0, 'down': 1, 'left': 2, 'right': 3}
        summary.sort(key=lambda x: order.get(x[0], 9))
        avg_recall = sum(r for _, r, _, _ in summary) / len(summary)
        avg_ap = sum(a for _, _, a, _ in summary) / len(summary)
        print('\n=== Summary (FP={}) ==='.format(args.fp_target))
        for orientation, recall, ap_fp, fps in summary:
            print(f'  {orientation.capitalize():>5}: Recall={recall * 100:.2f}%  AP={ap_fp * 100:.2f}%  |  FPS={fps:.2f}')
        print(f'  Avg : Recall={avg_recall * 100:.2f}%  AP={avg_ap * 100:.2f}%')


if __name__ == '__main__':
    main()
